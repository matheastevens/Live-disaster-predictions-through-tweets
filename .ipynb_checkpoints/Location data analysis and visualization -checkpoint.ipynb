{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mapping Disasters Based on Location Keyword Extraction\n",
    "\n",
    "Of tweets scraped from Twitter, only 30% of tweets actually contain location tagging. This means that 70% of all Tweets have no location-related information built in, making it difficult to aggregate locations and flag an actual suspected disaster. The content of tweets, however, will often mention a location (ie. \"Forest fire in LA County\") when a disaster is occurring. \n",
    "\n",
    "The goal of this notebook, therefore, is to develop an algorithm which can, in real time, scan all scraped tweets for location keywords. Once relevant locations have been extracted, they can be paired with their corresponding latitude and longitude coordinates and plotted on a Google map. \n",
    "\n",
    "This functionality with Google maps is a paid API with a ~7-day trial period, and therefore will not be immediately reproduceable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install gmplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import itertools\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "import re\n",
    "from collections import defaultdict\n",
    "from gmplot import gmplot\n",
    "\n",
    "import warnings\n",
    "from statistics import mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in cleaned Tweets\n",
    "\n",
    "df = pd.read_csv('data/sample_tweets_to_predict.csv')\n",
    "df.rename(columns = {'text':'tweet'}, inplace = True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_tweet():\n",
    "    tokenizer = RegexpTokenizer('\\w+|\\$[\\d\\.]\\S+')\n",
    "    lem = WordNetLemmatizer()\n",
    "    STOPWORDS = set(stopwords.words('english'))\n",
    "    df['processed_tweets'] = df['tweet'].apply(tokenizer.tokenize)\n",
    "    df['processed_tweets'] = df['processed_tweets'].apply(lambda row: list([lem.lemmatize(i) for i in row]))\n",
    "    df['processed_tweets'] = df['processed_tweets'].apply(lambda x:[i for i in x if i not in STOPWORDS] )\n",
    "    \n",
    "    return df\n",
    " \n",
    "#call the function\n",
    "process_tweet()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in city data: \n",
    "\n",
    "cities = pd.read_csv('https://raw.git.generalassemb.ly/noahszuckerman/project-5-natty-ds/master/data/worldcities.csv?token=AAAH7Z45CMEZ3KD2BQCU23LAGU4UQ', encoding = 'latin')\n",
    "cities.drop(columns = ['city_ascii', 'iso2', 'iso3', 'admin_name', 'capital',\n",
    "       'population', 'id'], axis = 1, inplace = True)\n",
    "\n",
    "#Create a dictionary to decrease computational complexity when searching over tweets for keywords.\n",
    "select_cities = cities.loc[(cities['country'] == 'United States') | (cities['country'] == 'Canada')]\n",
    "select_cities = select_cities['city'].tolist()\n",
    "select_cities = [x.lower() for x in select_cities]\n",
    "\n",
    "latitude = cities['lat'].tolist()\n",
    "longitude = cities['lng'].tolist()\n",
    "\n",
    "select_coords = list(zip(cities['lat'], cities['lng']))\n",
    "city_dict = dict(zip(select_cities,select_coords))\n",
    "\n",
    "\n",
    "coords_dict = defaultdict(dict)\n",
    "for x, y, z in zip(select_cities, latitude, longitude):\n",
    "    coords_dict[x] = y, z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "location = []\n",
    "array = [[]]\n",
    "\n",
    "\n",
    "for tweet in df['processed_tweets']:\n",
    "    \n",
    "    for word in tweet:\n",
    "        try:\n",
    "            city_dict[word]\n",
    "            location.append(tweet)\n",
    "            location.append(word)\n",
    "            array.append(location)\n",
    "            location = []       \n",
    "                \n",
    "        except:\n",
    "            location.append(tweet)\n",
    "            location.append('No Location Available')\n",
    "            array.append(location)\n",
    "            location = []\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.DataFrame(array, columns = ['tweet', 'location'])\n",
    "X.drop([0], inplace = True)\n",
    "\n",
    "X['tweet'] = [' '.join(map(str, l)) for l in X['tweet']]\n",
    "\n",
    "X.drop_duplicates(inplace = True)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Location Coordinates \n",
    "\n",
    "For each location extracted from tweets, the below functions map the corresponding longitude and latitude coordinates to the location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coordinates_list = [] \n",
    "cord_list = []\n",
    "lat = []\n",
    "long = []\n",
    "latitude_list = []\n",
    "longitude_list = []\n",
    "\n",
    "\n",
    "for word in X['location']:\n",
    "    try:\n",
    "        coords_dict[word]\n",
    "        lat.append(coords_dict[word][0])\n",
    "        latitude_list.append(lat)\n",
    "        long.append(coords_dict[word][1])\n",
    "        longitude_list.append(long)\n",
    "        lat = []\n",
    "        long = []\n",
    "        \n",
    "        \n",
    "\n",
    "    except:\n",
    "        lat = []\n",
    "        long =[]\n",
    "\n",
    "flat_lat = [item for sublist in latitude_list for item in sublist]\n",
    "flat_long = [item for sublist in longitude_list for item in sublist]    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mapping with Google Maps\n",
    "\n",
    "For each location, the below code superimposes the locations over a Google map using the gmplot module. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "gmap3 = gmplot.GoogleMapPlotter(39.822949,-121.41392, 26, apikey = \"INSERT YOUR API KEY HERE\")\n",
    "  \n",
    "# scatter method of map object  \n",
    "# scatter points on the google map \n",
    "gmap3.scatter(flat_lat, flat_long, size = 1000, marker = True, color = 'red' ) \n",
    "# Get an output html file of all plots  \n",
    "gmap3.draw(\"maps/my_map.html\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create GMapOptions object with map zoom\n",
    "map_options = GMapOptions(flat_lat.mean(), lng = flat_long.mean(), map_type='roadmap', zoom=8)\n",
    "api_key = os.environ['APIKey']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CREATING A HEAT MAP WITH LOCATIONS \n",
    "\n",
    "\n",
    "#declare the center of the map, and how much we want the map zoomed in\n",
    "gmap = gmplot.GoogleMapPlotter(0, 0, 2)\n",
    "# plot heatmap\n",
    "gmap.heatmap(flat_lat, flat_long)\n",
    "gmap.scatter(flat_lat, flat_long, c='r', marker=True)\n",
    "#Your Google_API_Key\n",
    "gmap.apikey = \"INSERT YOUR API KEY HERE\"\n",
    "# save it to html\n",
    "gmap.draw(\"./maps/country_heatmap.html\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
